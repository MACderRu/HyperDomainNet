exp:
  config_dir: /Users/vadimtitov/CLIPResearch/configs/
  config: multidomain.yaml
  project: nada
  name: multiple-mtg-test
  tags: 
    - mapper
    - mtg
  seed: 1
  root: .
  notes: empty notes
  step_save: 100000
  trainer: multiple_image_domain_adaptation_mtg
  multi_gpu: true
  dump_metrics: true
pretraining:
  do: false
  iter_num: 20000
  batch_size: 48
  mixing_noise: 0.9
  loss_funcs:
    - target_target
    - global
  loss_coefs:
    - 1.0
    - 1.0
training:
  iter_num: 2000
  batch_size: 10
  device: cuda:0
  patch_key: channelwise_sep_mult
  domain_list: core/image_list.txt
  test_domain_list: core/test_image_list.txt
  mixing_noise: 0.9
  mapper_config:
    backbone_type: shared
    mapper_type: residual_channelwise_sep
    activation: relu
    input_dimension: 512
    width: 512
    head_depth: 6
    backbone_depth: 8
    no_coarse: false
    no_fine: false
    no_medium: false
optimization_setup:
  visual_encoders:
    - ViT-B/32
    - ViT-B/16
  loss_funcs:
    - —Ålip_across
    - clip_within
    - clip_ref
    - l2_rec
    - lpips_rec
  loss_coefs:
    - 1.0
    - 0.5
    - 30.0
    - 10.0
    - 10.0
  optimizer:
    weight_decay: 0.0
    lr: 0.00002
    betas:
    - 0.0
    - 0.999
  weights_delta_l2_coef: 0.2
generator_setup:
  weights_path: pretrained/StyleGAN2/stylegan2-ffhq-config-f.pt
logging:
  log_every: 10
  log_images: 50
  latents_to_edit: []
  image_embedding_log: false
  truncation: 0.7
  num_grid_outputs: 2
evaluation:
  vision_models:
    - ViT-B/32
    - ViT-L/14
  step: 250
  data_size: 500
  batch_size: 24
checkpointing:
  is_on: false
  start_from: false
  step_backup: 10000000